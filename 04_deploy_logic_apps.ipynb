{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Logic Apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To operationalize our batch scoring workflow, we need a way to trigger our pipeline. Since we're applying style transfer to video data, lets trigger the pipeline everytime a new video is uploaded and detected. To do this, we'll need a mechanism that can detect the appearance of new video data. \n",
    "\n",
    "Logic Apps can solve this problem for us. In this notebook, we'll deploy a pre-built logic app that will look for new videos that appear in a specified storage location. When a new video is detected, the logic app will send an http request to the published pipeline (which we deployed in the previous notebook). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the packages we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Run, Experiment\n",
    "from azureml.pipeline.core import PublishedPipeline\n",
    "from azureml.core.datastore import Datastore\n",
    "from azure.mgmt.resource.resources.models import DeploymentMode\n",
    "from azure.mgmt.resource import ResourceManagementClient\n",
    "from azure.common.credentials import ServicePrincipalCredentials\n",
    "from dotenv import set_key, get_key, find_dotenv, load_dotenv\n",
    "from azureml.core.authentication import AzureCliAuthentication\n",
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_path = find_dotenv(raise_error_if_not_found=True)\n",
    "load_dotenv(env_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load our workspace from the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "stripout"
    ]
   },
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "# Also create a Project and attach to Workspace\n",
    "project_folder = \"scripts\"\n",
    "run_history_name = project_folder\n",
    "\n",
    "if not os.path.isdir(project_folder):\n",
    "    os.mkdir(project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get authentication information about our published pipeline so that we can use it during the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline = PublishedPipeline.get_published_pipeline(ws, id=get_key(env_path, \"AML_PUBLISHED_PIPELINE_ID\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cli_auth = AzureCliAuthentication()\n",
    "aad_token = cli_auth.get_authentication_header()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create service principle credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create service principle credentials which are used to deploy the Logic App."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = !az ad sp create-for-rbac -o json --query \"[appId, password, tenant]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "[sp_client, sp_secret, sp_tenant] = re.findall(\"\\w{8}[-]\\w{4}[-]\\w{4}[-]\\w{4}[-]\\w{12}\", str(credentials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'SP_SECRET', '6a0e7f2a-cf60-4aa5-ad6c-2ff218ed0fe2')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_key(env_path, \"SP_CLIENT\", sp_client) # generated\n",
    "set_key(env_path, \"SP_TENANT\", sp_tenant) # generated\n",
    "set_key(env_path, \"SP_SECRET\", sp_secret) # generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Logic App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Logic Apps](https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/azure_logic_app.jpg)\n",
    "\n",
    "The *logic* behind the Logic App deployment is shown above:\n",
    "1. When a blob is added, begin the workflow.\n",
    "2. Check the blob name. \n",
    "    - if the blob name ends with `.mp4`:\n",
    "        - make a request to the AKS endpoint\n",
    "    - otherwise:\n",
    "        - terminate in cancellation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up credentials and resource management client to create ARM deployments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create credentials and ARM client\n",
    "credentials = ServicePrincipalCredentials(client_id=sp_client,\n",
    "                                          secret=sp_secret,\n",
    "                                          tenant=sp_tenant)\n",
    "\n",
    "resource_client = ResourceManagementClient(credentials, get_key(env_path, \"SUBSCRIPTION_ID\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the deployment for the Azure blob storage connector.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<msrest.polling.poller.LROPoller at 0x7f4fa191a160>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an Azure Blob Storage connector\n",
    "with open('template.blob_connector.json') as f:\n",
    "    blob_con_template = json.load(f)\n",
    "\n",
    "blob_con_params = {\n",
    "    \"location\": {\"value\": get_key(env_path, \"REGION\")},\n",
    "    \"subscription_id\": {\"value\": get_key(env_path, \"SUBSCRIPTION_ID\")}\n",
    "}\n",
    "\n",
    "blob_con_props = {\n",
    "    'mode': DeploymentMode.incremental,\n",
    "    'template': blob_con_template,\n",
    "    'parameters': blob_con_params\n",
    "}\n",
    "\n",
    "resource_client.deployments.create_or_update(\n",
    "    resource_group_name=get_key(env_path, \"RESOURCE_GROUP\"), \n",
    "    deployment_name=\"blob_connector\", \n",
    "    properties=blob_con_props\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the deployment for the Logic App."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<msrest.polling.poller.LROPoller at 0x7f4fb09b2c18>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Logic App\n",
    "with open('template.logic_app.json') as f:\n",
    "    logic_app_template = json.load(f)\n",
    "\n",
    "logic_app_params = {\n",
    "    \"location\": {\"value\": get_key(env_path, \"REGION\")},\n",
    "    \"resource_group\": { \"value\": get_key(env_path, \"RESOURCE_GROUP\") },\n",
    "    \"name\": {\"value\": \"logic_app\"},\n",
    "    \"subscription_id\": {\"value\": get_key(env_path, \"SUBSCRIPTION_ID\")},\n",
    "    \"storage_container_name\": {\"value\": get_key(env_path, \"STORAGE_CONTAINER_NAME\")},\n",
    "    \"url_endpoint\": {\"value\": published_pipeline.endpoint},\n",
    "    \"aad_token\": {\"value\": aad_token[\"Authorization\"]},\n",
    "    \"datastore_name\": {\"value\": get_key(env_path, \"AML_DATASTORE_NAME\")}, \n",
    "    \"experiment_name\": {\"value\": \"logic_app_experiment\"}\n",
    "}\n",
    "\n",
    "logic_app_props = {\n",
    "    'mode': DeploymentMode.incremental,\n",
    "    'template': logic_app_template,\n",
    "    'parameters': logic_app_params\n",
    "}\n",
    "\n",
    "resource_client.deployments.create_or_update(\n",
    "    resource_group_name=get_key(env_path, \"RESOURCE_GROUP\"), \n",
    "    deployment_name=\"logic_app\", \n",
    "    properties=logic_app_props\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the Logic App is deployed, go into the Azure portal and the Azure blob connector to authenticate. \n",
    "\n",
    "When you open up up the Azure blob connector, it should look like this:\n",
    "\n",
    "![azure_blob_connector_auth](https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/azure_blob_connector_auth.PNG)\n",
    "\n",
    "For the connector, click on the orange bar at the top to authenticate.\n",
    "\n",
    "Once authenticated, your Logic App should be all set up and ready to trigger the workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigger logic app by adding a new video to the Azure blob container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp orangutan.mp4 trigger_test_orangutan.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_datastore = Datastore.register_azure_blob_container(\n",
    "    workspace=ws, \n",
    "    datastore_name=get_key(env_path, \"AML_DATASTORE_NAME\"), \n",
    "    container_name=get_key(env_path, \"STORAGE_CONTAINER_NAME\"), \n",
    "    account_name=get_key(env_path, \"STORAGE_ACCOUNT_NAME\"), \n",
    "    account_key=get_key(env_path, \"STORAGE_ACCOUNT_KEY\"),\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_datastore"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload new trigger file video\n",
    "my_datastore.upload_files(\n",
    "    [\"./trigger_test_orangutan.mp4\"],\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The appearance of the new `trigger_test_orangutan.mp4` video will trigger the Logic App flow. Inspect your logic app in the portal to see the progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now ready to move on to the [next notebook](05_clean_up.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:batchscoringdl_aml]",
   "language": "python",
   "name": "conda-env-batchscoringdl_aml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
