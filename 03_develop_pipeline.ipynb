{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import package and load .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import set_key, get_key, find_dotenv, load_dotenv\n",
    "from pathlib import Path\n",
    "from azureml.core import Workspace, Run, Experiment\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.core.datastore import Datastore\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.pipeline.core import Pipeline, PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep, MpiStep\n",
    "from azureml.core.runconfig import CondaDependencies, RunConfiguration\n",
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE #, DEFAULT_GPU_IMAGE\n",
    "from IPython.core.display import display, HTML\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = find_dotenv(raise_error_if_not_found=True)\n",
    "load_dotenv(env_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the workspace in AML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get our workspace from the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "# Also create a Project and attach to Workspace\n",
    "project_folder = \"scripts\"\n",
    "run_history_name = project_folder\n",
    "\n",
    "if not os.path.isdir(project_folder):\n",
    "    os.mkdir(project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our compute using `AmlCompute`. We'll need one node for the video pre/post processing. And the remaining nodes for performing the style transfer. Since we'll be using the MPI Step, all nodes must be active before the MPI step will execute. Thus, we should set max nodes to equal min nodes, as there is no point autoscaling the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_transfer_node_count = 4\n",
    "ffmpeg_node_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU compute\n",
    "cpu_cluster_name = \"ffmpeg-cluster\"\n",
    "try:\n",
    "    cpu_cluster = AmlCompute(ws, cpu_cluster_name)\n",
    "    print(\"Found existing cluster.\")\n",
    "except:\n",
    "    print(\"Creating {}\".format(cpu_cluster_name))\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=\"STANDARD_D3_V2\", \n",
    "        min_nodes=ffmpeg_node_count, \n",
    "        max_nodes=ffmpeg_node_count\n",
    "    )\n",
    "\n",
    "    # create the cluster\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, provisioning_config)\n",
    "    cpu_cluster.wait_for_completion(show_output=True)\n",
    "    \n",
    "# GPU compute\n",
    "gpu_cluster_name = \"style-cluster\"\n",
    "try:\n",
    "    gpu_cluster = AmlCompute(ws, gpu_cluster_name)\n",
    "    print(\"Found existing cluster.\")\n",
    "except:\n",
    "    print(\"Creating {}\".format(gpu_cluster_name))\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=\"STANDARD_NC6s_v3\", \n",
    "        min_nodes=style_transfer_node_count, \n",
    "        max_nodes=style_transfer_node_count\n",
    "    )\n",
    "\n",
    "    # create the cluster\n",
    "    gpu_cluster = ComputeTarget.create(ws, gpu_cluster_name, provisioning_config)\n",
    "    gpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup data references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a datastore based on the storage account we created earlier. We'll use that storage account to hold our input and output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datastore\n",
    "my_datastore = Datastore.register_azure_blob_container(\n",
    "    workspace=ws, \n",
    "    datastore_name=\"datastore\", \n",
    "    container_name=get_key(env_path, \"STORAGE_CONTAINER_NAME\"), \n",
    "    account_name=get_key(env_path, \"STORAGE_ACCOUNT_NAME\"), \n",
    "    account_key=get_key(env_path, \"STORAGE_ACCOUNT_KEY\"),\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the `models` folder (from out local directory) and the `orangutan.mp4` video to the datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload files in models folder to a directory called models\n",
    "my_datastore.upload_files(\n",
    "    [\"./models/model.pth\"],\n",
    "    target_path=\"models\", \n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# Upload orangutan.mp4 video\n",
    "my_datastore.upload_files(\n",
    "    [\"./orangutan.mp4\"],\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the `models` dir and the `orangutan.mp4` video we upload as data references to be used by the pipeline steps later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = DataReference(\n",
    "    data_reference_name=\"model_dir\", \n",
    "    datastore=my_datastore, \n",
    "    path_on_datastore=\"models\", \n",
    "    mode=\"download\"\n",
    ")\n",
    "\n",
    "video = DataReference(\n",
    "    datastore=my_datastore,                        \n",
    "    data_reference_name=\"video\",\n",
    "    path_on_datastore=\"orangutan.mp4\", \n",
    "    mode=\"download\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the output video to be saved in the same datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_video = PipelineData(name=\"output_video\", datastore=my_datastore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a reference to the datastore that was generated when the AML workspace was created. We'll use this datastore to hold temporary pipeline data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_datastore = ws.get_default_datastore()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save all temporary data files (PipelineData) to the default datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffmpeg_audio = PipelineData(name=\"ffmpeg_audio\", datastore=default_datastore)\n",
    "ffmpeg_images = PipelineData(name=\"ffmpeg_images\", datastore=default_datastore)\n",
    "processed_images = PipelineData(name=\"processed_images\", datastore=default_datastore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup cluster environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config for ffmpeg cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffmpeg_cd = CondaDependencies()\n",
    "ffmpeg_cd.add_channel(\"conda-forge\")\n",
    "ffmpeg_cd.add_conda_package(\"ffmpeg\")\n",
    "\n",
    "ffmpeg_run_config = RunConfiguration(conda_dependencies=ffmpeg_cd)\n",
    "ffmpeg_run_config.environment.docker.enabled = True\n",
    "ffmpeg_run_config.environment.docker.gpu_support = False\n",
    "ffmpeg_run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "ffmpeg_run_config.environment.spark.precache_packages = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config for style transfer cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_transfer_cd = CondaDependencies()\n",
    "style_transfer_cd.add_channel(\"pytorch\")\n",
    "style_transfer_cd.add_conda_package(\"pytorch\")\n",
    "\n",
    "style_transfer_run_config = RunConfiguration(conda_dependencies=style_transfer_cd)\n",
    "style_transfer_run_config.environment.docker.enabled = True\n",
    "style_transfer_run_config.environment.docker.gpu_support = True\n",
    "style_transfer_run_config.environment.docker.base_image = \"pytorch/pytorch\"\n",
    "style_transfer_run_config.environment.spark.precache_packages = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up pipeline steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# style_param = PipelineParameter(name=\"style\", default_value=\"mosaic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_video_step = PythonScriptStep(\n",
    "    name=\"preprocess video\",\n",
    "    script_name=\"preprocess_video.py\",\n",
    "    arguments=[\"--input-video\", video,\n",
    "               \"--output-audio\", ffmpeg_audio,\n",
    "               \"--output-images\", ffmpeg_images,\n",
    "              ],\n",
    "    compute_target=cpu_cluster,\n",
    "    inputs=[video],\n",
    "    outputs=[ffmpeg_images, ffmpeg_audio],\n",
    "    runconfig=ffmpeg_run_config,\n",
    "    source_directory=project_folder,\n",
    "    allow_reuse=False\n",
    ")\n",
    "\n",
    "distributed_style_transfer_step = MpiStep(\n",
    "    name=\"mpi style transfer\",\n",
    "    script_name=\"style_transfer_mpi.py\",\n",
    "    arguments=[\"--content-dir\", ffmpeg_images,\n",
    "               \"--output-dir\", processed_images,\n",
    "               \"--model-dir\", model_dir,\n",
    "               \"--cuda\", 1\n",
    "              ],\n",
    "    compute_target=gpu_cluster,\n",
    "    node_count=4, \n",
    "    process_count_per_node=1,\n",
    "    inputs=[model_dir, ffmpeg_images],\n",
    "    outputs=[processed_images],\n",
    "    pip_packages=[\"image\", \"mpi4py\", \"torch\", \"torchvision\"],\n",
    "    runconfig=style_transfer_run_config,\n",
    "    use_gpu=True,\n",
    "    source_directory=project_folder,\n",
    "    allow_reuse=False\n",
    ")\n",
    "\n",
    "postprocess_video_step = PythonScriptStep(\n",
    "    name=\"postprocess video\",\n",
    "    script_name=\"postprocess_video.py\",\n",
    "    arguments=[\"--images-dir\", processed_images, \n",
    "               \"--input-audio\", ffmpeg_audio, \n",
    "               \"--output-dir\", output_video],\n",
    "    compute_target=cpu_cluster,\n",
    "    inputs=[processed_images, ffmpeg_audio],\n",
    "    outputs=[output_video],\n",
    "    runconfig=ffmpeg_run_config,\n",
    "    source_directory=project_folder,\n",
    "    allow_reuse=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [preprocess_video_step, distributed_style_transfer_step, postprocess_video_step]\n",
    "pipeline = Pipeline(workspace=ws, steps=steps)\n",
    "pipeline_run = Experiment(ws, 'style_transfer_mpi').submit(pipeline)\n",
    "# pipeline_run = Experiment(ws, 'style_transfer_mpi').submit(pipeline, pipeline_params={\"style\": \"mosaic\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the output video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the step id of the postprocessing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_id = pipeline_run.find_step_run(\"postprocess video\")[0].id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the output files from the postprocessing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_datastore.download(\n",
    "    target_path=\"aml_test_orangutan\", \n",
    "    prefix=step_id, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the generated output video that we just downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(\"\"\"\n",
    "    <video width=\"320\" height=\"240\" controls>\n",
    "        <source src=\"aml_test_orangutan/{}/output_video/video_processed.mp4\" type=\"video/mp4\">\n",
    "    </video>\n",
    "\"\"\".format(step_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now ready to move on to the [next notebook](04_publish_pipeline.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path_param = PipelineParameter(name=\"video_path\", default_value=\"dne.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path_param.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = DataReference(\n",
    "    datastore=my_datastore,                        \n",
    "    data_reference_name=\"video\",\n",
    "    path_on_datastore=video_path_param, \n",
    "    mode=\"download\"\n",
    ")\n",
    "\n",
    "preprocess_video_step = PythonScriptStep(\n",
    "    name=\"preprocess video\",\n",
    "    script_name=\"preprocess_video.py\",\n",
    "    arguments=[\"--input-video\", video,\n",
    "               \"--output-audio\", ffmpeg_audio,\n",
    "               \"--output-images\", ffmpeg_images,\n",
    "              ],\n",
    "    compute_target=cpu_cluster,\n",
    "    inputs=[video],\n",
    "    outputs=[ffmpeg_images, ffmpeg_audio],\n",
    "    runconfig=ffmpeg_run_config,\n",
    "    source_directory=project_folder,\n",
    "    allow_reuse=False\n",
    ")\n",
    "\n",
    "distributed_style_transfer_step = MpiStep(\n",
    "    name=\"mpi style transfer\",\n",
    "    script_name=\"style_transfer_mpi.py\",\n",
    "    arguments=[\"--content-dir\", ffmpeg_images,\n",
    "               \"--output-dir\", processed_images,\n",
    "               \"--model-dir\", model_dir,\n",
    "               \"--cuda\", 1\n",
    "              ],\n",
    "    compute_target=gpu_cluster,\n",
    "    node_count=4, \n",
    "    process_count_per_node=1,\n",
    "    inputs=[model_dir, ffmpeg_images],\n",
    "    outputs=[processed_images],\n",
    "    pip_packages=[\"image\", \"mpi4py\", \"torch\", \"torchvision\"],\n",
    "    runconfig=style_transfer_run_config,\n",
    "    use_gpu=True,\n",
    "    source_directory=project_folder,\n",
    "    allow_reuse=False\n",
    ")\n",
    "\n",
    "postprocess_video_step = PythonScriptStep(\n",
    "    name=\"postprocess video\",\n",
    "    script_name=\"postprocess_video.py\",\n",
    "    arguments=[\"--images-dir\", processed_images, \n",
    "               \"--input-audio\", ffmpeg_audio, \n",
    "               \"--output-dir\", output_video],\n",
    "    compute_target=cpu_cluster,\n",
    "    inputs=[processed_images, ffmpeg_audio],\n",
    "    outputs=[output_video],\n",
    "    runconfig=ffmpeg_run_config,\n",
    "    source_directory=project_folder,\n",
    "    allow_reuse=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [postprocess_video_step]\n",
    "pipeline = Pipeline(workspace=ws, steps=steps)\n",
    "pipeline_run = Experiment(ws, 'style_transfer_mpi_param').submit(\n",
    "    pipeline, \n",
    "    pipeline_params={\"video_path\": \"orangutan.mp4\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:batchscoringdl_aml]",
   "language": "python",
   "name": "conda-env-batchscoringdl_aml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
