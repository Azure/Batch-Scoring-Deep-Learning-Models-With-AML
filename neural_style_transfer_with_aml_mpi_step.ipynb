{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azureml.core import Workspace, Run, Experiment\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "# Also create a Project and attach to Workspace\n",
    "project_folder = \"scripts2\"\n",
    "run_history_name = project_folder\n",
    "\n",
    "if not os.path.isdir(project_folder):\n",
    "    os.mkdir(project_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.core.datastore import Datastore\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.pipeline.core import Pipeline, PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep, MpiStep\n",
    "from azureml.core.runconfig import CondaDependencies, RunConfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU compute\n",
    "cpu_cluster_name = \"ffmpeg-cluster\"\n",
    "try:\n",
    "    cpu_cluster = AmlCompute(ws, cpu_cluster_name)\n",
    "    print(\"Found existing cluster.\")\n",
    "except:\n",
    "    print(\"Creating {}\".format(cpu_cluster_name))\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D2s_v3\", min_nodes=1, max_nodes=1)\n",
    "\n",
    "    # create the cluster\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, provisioning_config)\n",
    "    cpu_cluster.wait_for_completion(show_output=True)\n",
    "    \n",
    "# GPU compute\n",
    "gpu_cluster_name = \"style-cluster\"\n",
    "try:\n",
    "    gpu_cluster = AmlCompute(ws, gpu_cluster_name)\n",
    "    print(\"Found existing cluster.\")\n",
    "except:\n",
    "    print(\"Creating {}\".format(gpu_cluster_name))\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_NC6s_v3\", min_nodes=4, max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    gpu_cluster = ComputeTarget.create(ws, gpu_cluster_name, provisioning_config)\n",
    "    gpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $project_folder/process_video.py\n",
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Process input video\")\n",
    "parser.add_argument('--input-video', required=True)\n",
    "parser.add_argument('--output-audio', required=True)\n",
    "parser.add_argument('--output-images', required=True)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "os.makedirs(args.output_audio, exist_ok=True)\n",
    "os.makedirs(args.output_images, exist_ok=True)\n",
    "\n",
    "subprocess.run(\"ffmpeg -i {} {}/video.aac\"\n",
    "              .format(args.input_video, args.output_audio),\n",
    "               shell=True, check=True\n",
    "              )\n",
    "\n",
    "subprocess.run(\"ffmpeg -i {} {}/%05d_video.jpg -hide_banner\"\n",
    "              .format(args.input_video, args.output_images),\n",
    "               shell=True, check=True\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $project_folder/stitch_video.py\n",
    "import argparse\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Process input video\")\n",
    "parser.add_argument('--images-dir', required=True)\n",
    "parser.add_argument('--input-audio', required=True)\n",
    "parser.add_argument('--output-dir', required=True)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "subprocess.run(\"ffmpeg -framerate 30 -i {}/%05d_video.jpg -c:v libx264 -profile:v high -crf 20 -pix_fmt yuv420p \"\n",
    "               \"-y {}/video_without_audio.mp4\"\n",
    "               .format(args.images_dir, args.output_dir),\n",
    "               shell=True, check=True\n",
    "              )\n",
    "\n",
    "subprocess.run(\"ffmpeg -i {}/video_without_audio.mp4 -i {}/video.aac -map 0:0 -map 1:0 -vcodec \"\n",
    "               \"copy -acodec copy -y {}/video_with_audio.mp4\"\n",
    "               .format(args.output_dir, args.input_audio, args.output_dir),\n",
    "               shell=True, check=True\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datastore for input video\n",
    "account_name = \"happypathspublic\"\n",
    "video_ds = Datastore.register_azure_blob_container(\n",
    "    ws, \n",
    "    \"videos\", \n",
    "    \"videos\", \n",
    "    account_name=account_name, \n",
    "    overwrite=True)\n",
    "\n",
    "# datastore for models\n",
    "models_ds = Datastore.register_azure_blob_container(\n",
    "    ws, \n",
    "    \"models\", \n",
    "    \"styletransfer\", \n",
    "    account_name=\"pipelinedata\", \n",
    "    overwrite=True)\n",
    "                                                        \n",
    "# downloaded models from https://pytorch.org/tutorials/advanced/neural_style_tutorial.html are kept here\n",
    "models_dir = DataReference(data_reference_name=\"models\", datastore=models_ds, \n",
    "                           path_on_datastore=\"saved_models\", mode=\"download\")\n",
    "\n",
    "# the default blob store attached to a workspace\n",
    "default_datastore = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orangutan_video = DataReference(datastore=video_ds,\n",
    "                            data_reference_name=\"video\",\n",
    "                            path_on_datastore=\"nature.mp4\", mode=\"download\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = CondaDependencies()\n",
    "\n",
    "cd.add_channel(\"conda-forge\")\n",
    "cd.add_conda_package(\"ffmpeg\")\n",
    "\n",
    "cd.add_channel(\"pytorch\")\n",
    "cd.add_conda_package(\"pytorch\")\n",
    "cd.add_conda_package(\"torchvision\")\n",
    "\n",
    "cd.add_channel(\"anaconda\")\n",
    "cd.add_conda_package(\"mpi4py\")\n",
    "\n",
    "# Runconfig\n",
    "batchai_run_config = RunConfiguration(conda_dependencies=cd)\n",
    "batchai_run_config.environment.docker.enabled = True\n",
    "batchai_run_config.environment.docker.gpu_support = True\n",
    "batchai_run_config.environment.docker.base_image = \"pytorch/pytorch\"\n",
    "batchai_run_config.environment.spark.precache_packages = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffmpeg_audio = PipelineData(name=\"ffmpeg_audio\", datastore=default_datastore)\n",
    "ffmpeg_images = PipelineData(name=\"ffmpeg_images\", datastore=default_datastore)\n",
    "processed_images = PipelineData(name=\"processed_images\", datastore=default_datastore)\n",
    "output_video = PipelineData(name=\"output_video\", datastore=default_datastore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "#one of \"candy\", \"mosaic\", \"rain_princess\", \"udnie\" \n",
    "style_param = PipelineParameter(name=\"style\", default_value=\"mosaic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_video_step = PythonScriptStep(\n",
    "    name=\"split video\",\n",
    "    script_name=\"process_video.py\",\n",
    "    arguments=[\"--input-video\", orangutan_video,\n",
    "               \"--output-audio\", ffmpeg_audio,\n",
    "               \"--output-images\", ffmpeg_images,\n",
    "              ],\n",
    "    compute_target=cpu_cluster,\n",
    "    inputs=[orangutan_video],\n",
    "    outputs=[ffmpeg_images, ffmpeg_audio],\n",
    "    runconfig=batchai_run_config,\n",
    "    source_directory=project_folder,\n",
    "    allow_reuse=False\n",
    ")\n",
    "\n",
    "distributed_style_transfer_step = MpiStep(\n",
    "    name=\"mpi style transfer\",\n",
    "    script_name=\"neural_style_mpi.py\",\n",
    "    arguments=[\"--content-dir\", ffmpeg_images,\n",
    "               \"--output-dir\", processed_images,\n",
    "               \"--model-dir\", models_dir,\n",
    "               \"--style\", style_param,\n",
    "               \"--cuda\", 1\n",
    "              ],\n",
    "    compute_target=gpu_cluster,\n",
    "    node_count=3, \n",
    "    process_count_per_node=1,\n",
    "    inputs=[models_dir, ffmpeg_images],\n",
    "    outputs=[processed_images],\n",
    "    pip_packages=[\"mpi4py\", \"torch\", \"torchvision\"],\n",
    "    runconfig=batchai_run_config,\n",
    "    use_gpu=True,\n",
    "    source_directory=project_folder,\n",
    "    allow_reuse=False\n",
    ")\n",
    "\n",
    "stitch_video_step = PythonScriptStep(\n",
    "    name=\"stitch\",\n",
    "    script_name=\"stitch_video.py\",\n",
    "    arguments=[\"--images-dir\", processed_images, \n",
    "               \"--input-audio\", ffmpeg_audio, \n",
    "               \"--output-dir\", output_video],\n",
    "    compute_target=cpu_cluster,\n",
    "    inputs=[processed_images, ffmpeg_audio],\n",
    "    outputs=[output_video],\n",
    "    runconfig=batchai_run_config,\n",
    "    source_directory=project_folder,\n",
    "    allow_reuse=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(workspace=ws, steps=[stitch_video_step])\n",
    "pipeline_run = Experiment(ws, 'style_transfer_mpi_old').submit(pipeline)\n",
    "# pipeline_run = Experiment(ws, 'style_transfer_mpi_old').submit(pipeline, pipeline_params={\"style\": \"mosaic\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.widgets import RunDetails\n",
    "RunDetails(pipeline_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_video(run, target_dir=None):\n",
    "    stitch_run = run.find_step_run(\"stitch\")[0]\n",
    "    port_data = stitch_run.get_output_data(\"output_video\")\n",
    "    port_data.download(target_dir, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_video(pipeline_run, \"output_video2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline = pipeline_run.publish_pipeline(\n",
    "    name=\"batch score style transfer\", description=\"style transfer\", version=\"1.0\")\n",
    "\n",
    "published_id = published_pipeline.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:batchscoringdl_aml]",
   "language": "python",
   "name": "conda-env-batchscoringdl_aml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
